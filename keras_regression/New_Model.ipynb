{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07533bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import csv\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense , Dropout , Activation , Flatten\n",
    "from keras.layers.convolutional import Convolution1D, MaxPooling1D\n",
    "from keras.layers import Embedding, LSTM\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error , mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2a3b9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of the word embeddings\n",
    "embeddings_dim = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ed0525c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maximum number of words to consider in the representations\n",
    "max_features = 20000 #Voc is: 24535 but 10273 only (>2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd744df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maximum length of a sentence\n",
    "max_sent_len = 50 # Max 58, Median = 17, avg 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67e69a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "crossval = 20\n",
    "## Random Seed\n",
    "seed = 27\n",
    "#number of dimensions in regression problem\n",
    "reg_dimensions = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83c88072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading pre-trained word embeddings...\n",
      "Reading text data for regression and building representations...\n"
     ]
    }
   ],
   "source": [
    "print (\"\")\n",
    "print (\"Reading pre-trained word embeddings...\")\n",
    "embeddings = dict( )\n",
    "\n",
    "# Load external word embeddings\n",
    "embeddings = KeyedVectors.load_word2vec_format( \"twitter_sgns_subset.txt.gz\" , binary=False ) \n",
    "print (\"Reading text data for regression and building representations...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e363161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10941</td>\n",
       "      <td>At the point today where if someone says somet...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10942</td>\n",
       "      <td>@CorningFootball  IT'S GAME DAY!!!!      T MIN...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10943</td>\n",
       "      <td>This game has pissed me off more than any othe...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10944</td>\n",
       "      <td>@spamvicious I've just found out it's Candice ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10945</td>\n",
       "      <td>@moocowward @mrsajhargreaves @Melly77 @GaryBar...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7097</th>\n",
       "      <td>40855</td>\n",
       "      <td>Common app just randomly logged me out as I wa...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7098</th>\n",
       "      <td>40856</td>\n",
       "      <td>I'd rather laugh with the rarest genius, in be...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7099</th>\n",
       "      <td>40857</td>\n",
       "      <td>If you #invest in my new #film I will stop ask...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7100</th>\n",
       "      <td>40858</td>\n",
       "      <td>Just watched Django Unchained, Other people ma...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7101</th>\n",
       "      <td>40859</td>\n",
       "      <td>@KeithOlbermann depressing how despicable Trum...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7102 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SentID                                              Tweet  Emotion  \\\n",
       "0      10941  At the point today where if someone says somet...    anger   \n",
       "1      10942  @CorningFootball  IT'S GAME DAY!!!!      T MIN...    anger   \n",
       "2      10943  This game has pissed me off more than any othe...    anger   \n",
       "3      10944  @spamvicious I've just found out it's Candice ...    anger   \n",
       "4      10945  @moocowward @mrsajhargreaves @Melly77 @GaryBar...    anger   \n",
       "...      ...                                                ...      ...   \n",
       "7097   40855  Common app just randomly logged me out as I wa...  sadness   \n",
       "7098   40856  I'd rather laugh with the rarest genius, in be...  sadness   \n",
       "7099   40857  If you #invest in my new #film I will stop ask...  sadness   \n",
       "7100   40858  Just watched Django Unchained, Other people ma...  sadness   \n",
       "7101   40859  @KeithOlbermann depressing how despicable Trum...  sadness   \n",
       "\n",
       "      Rating  \n",
       "0      0.000  \n",
       "1      0.000  \n",
       "2      0.000  \n",
       "3      0.000  \n",
       "4      0.000  \n",
       "...      ...  \n",
       "7097   0.833  \n",
       "7098   0.688  \n",
       "7099   0.458  \n",
       "7100   0.333  \n",
       "7101   0.708  \n",
       "\n",
       "[7102 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"vocab.csv\", sep='\\t')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f19ddd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We first estimate the entire vocabulary, here we use a file that combines Test&Train data:\n",
    "\n",
    "full_voc_data  = list(df[[\"Tweet\",\"Rating\"]].itertuples(index=False, name=None))\n",
    "full_data_size = int(len(full_voc_data))\n",
    "all_texts = [txt for (txt, label) in full_voc_data[0:full_data_size] ]\n",
    "tokenizer = Tokenizer(num_words=max_features, filters='%&()*+,-./:;<=>[\\\\]^_`{|}~\\t\\n',lower=True, split=\" \")\n",
    "tokenizer.fit_on_texts(all_texts) # <-- Tokenizer based on all TEXTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e0f6723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>At the point today where if someone says somet...</td>\n",
       "      <td>0.319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@CorningFootball  IT'S GAME DAY!!!!      T MIN...</td>\n",
       "      <td>0.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This game has pissed me off more than any othe...</td>\n",
       "      <td>0.898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@spamvicious I've just found out it's Candice ...</td>\n",
       "      <td>0.271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@moocowward @mrsajhargreaves @Melly77 @GaryBar...</td>\n",
       "      <td>0.646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>@ggreenwald What if the supposed animosity is ...</td>\n",
       "      <td>0.646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>Will BYU's offense score 24+ vs WVU?</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>Id love 2 c Gyimah in action but his coach is ...</td>\n",
       "      <td>0.542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>Forgiving means operating with God's spirit &amp;a...</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>i've got a lot of tokens saved up and i wanna ...</td>\n",
       "      <td>0.417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>760 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Tweet  Rating\n",
       "0    At the point today where if someone says somet...   0.319\n",
       "1    @CorningFootball  IT'S GAME DAY!!!!      T MIN...   0.144\n",
       "2    This game has pissed me off more than any othe...   0.898\n",
       "3    @spamvicious I've just found out it's Candice ...   0.271\n",
       "4    @moocowward @mrsajhargreaves @Melly77 @GaryBar...   0.646\n",
       "..                                                 ...     ...\n",
       "755  @ggreenwald What if the supposed animosity is ...   0.646\n",
       "756               Will BYU's offense score 24+ vs WVU?   0.125\n",
       "757  Id love 2 c Gyimah in action but his coach is ...   0.542\n",
       "758  Forgiving means operating with God's spirit &a...   0.250\n",
       "759  i've got a lot of tokens saved up and i wanna ...   0.417\n",
       "\n",
       "[760 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"test/anger_CNN-LSTM_input.txt\", sep='\\t')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d83104e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOW LOAD TEST DATA ##\n",
    "TSdata = list(test[[\"Tweet\",\"Rating\"]].itertuples(index=False, name=None))\n",
    "test_size = int(len(TSdata) )\n",
    "test_texts = [ txt for ( txt, label ) in TSdata[0:test_size] ]\n",
    "test_labels = [ label for ( txt , label ) in TSdata[0:test_size] ]\n",
    "test_sequences = sequence.pad_sequences( tokenizer.texts_to_sequences( test_texts ) , maxlen=max_sent_len )\n",
    "##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b025e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "59/59 [==============================] - 13s 109ms/step - loss: 0.13403s - l\n",
      "Epoch 2/30\n",
      "59/59 [==============================] - 9s 153ms/step - loss: 0.1158\n",
      "Epoch 3/30\n",
      "59/59 [==============================] - 7s 113ms/step - loss: 0.0887\n",
      "Epoch 4/30\n",
      "59/59 [==============================] - 6s 109ms/step - loss: 0.0752 1\n",
      "Epoch 5/30\n",
      "59/59 [==============================] - 7s 114ms/step - loss: 0.0640\n",
      "Epoch 6/30\n",
      "59/59 [==============================] - 6s 109ms/step - loss: 0.0586\n",
      "Epoch 7/30\n",
      "59/59 [==============================] - 7s 111ms/step - loss: 0.0510\n",
      "Epoch 8/30\n",
      "59/59 [==============================] - 6s 106ms/step - loss: 0.0485\n",
      "Epoch 9/30\n",
      "59/59 [==============================] - 6s 103ms/step - loss: 0.0446\n",
      "Epoch 10/30\n",
      "59/59 [==============================] - 6s 103ms/step - loss: 0.0428\n",
      "Epoch 11/30\n",
      "59/59 [==============================] - 7s 113ms/step - loss: 0.0401\n",
      "Epoch 12/30\n",
      "59/59 [==============================] - 6s 110ms/step - loss: 0.0391\n",
      "Epoch 13/30\n",
      "59/59 [==============================] - 6s 103ms/step - loss: 0.0367\n",
      "Epoch 14/30\n",
      "59/59 [==============================] - 6s 103ms/step - loss: 0.0358\n",
      "Epoch 15/30\n",
      "59/59 [==============================] - 6s 102ms/step - loss: 0.0327\n",
      "Epoch 16/30\n",
      "59/59 [==============================] - 6s 103ms/step - loss: 0.0346\n",
      "Epoch 17/30\n",
      "59/59 [==============================] - 6s 105ms/step - loss: 0.0323\n",
      "Epoch 18/30\n",
      "59/59 [==============================] - 6s 107ms/step - loss: 0.0299\n",
      "Epoch 19/30\n",
      "59/59 [==============================] - 6s 106ms/step - loss: 0.0311\n",
      "Epoch 20/30\n",
      "59/59 [==============================] - 6s 109ms/step - loss: 0.0299\n",
      "Epoch 21/30\n",
      "59/59 [==============================] - 6s 104ms/step - loss: 0.0280\n",
      "Epoch 22/30\n",
      "59/59 [==============================] - 6s 107ms/step - loss: 0.0280\n",
      "Epoch 23/30\n",
      "59/59 [==============================] - 6s 108ms/step - loss: 0.0264\n",
      "Epoch 24/30\n",
      "59/59 [==============================] - 6s 102ms/step - loss: 0.0249\n",
      "Epoch 25/30\n",
      "59/59 [==============================] - 6s 105ms/step - loss: 0.0273\n",
      "Epoch 26/30\n",
      "59/59 [==============================] - 6s 105ms/step - loss: 0.0258\n",
      "Epoch 27/30\n",
      "59/59 [==============================] - 6s 107ms/step - loss: 0.0235\n",
      "Epoch 28/30\n",
      "59/59 [==============================] - 6s 102ms/step - loss: 0.0241\n",
      "Epoch 29/30\n",
      "59/59 [==============================] - 6s 103ms/step - loss: 0.0240\n",
      "Epoch 30/30\n",
      "59/59 [==============================] - 6s 103ms/step - loss: 0.0215\n"
     ]
    }
   ],
   "source": [
    "## we Iterate through all training types, as well as the combination (afjs):\n",
    "## Note that afjs is (yet) not used by our system.\n",
    "EMOS=\"anger\"\n",
    "for i in EMOS.split():\n",
    "    currentemo=str(i)\n",
    "    temp_df = pd.read_csv(\"train/\"+currentemo+\"_tr_dv.csv\", sep='\\t')\n",
    "    TRdata = list(temp_df[[\"Tweet\",\"Rating\"]].itertuples(index=False, name=None))\n",
    "    random.shuffle( TRdata )    \n",
    "    train_size = int(len(TRdata) )\n",
    "    train_texts = [ txt for ( txt, label ) in TRdata[0:train_size] ]\n",
    "    train_labels = [ label for ( txt , label ) in TRdata[0:train_size] ]\n",
    "    train_sequences = sequence.pad_sequences( tokenizer.texts_to_sequences( train_texts ) , maxlen=max_sent_len )\n",
    "    embedding_weights = np.zeros( ( max_features , embeddings_dim ) )\n",
    "    for word,index in tokenizer.word_index.items():\n",
    "        if index < max_features:\n",
    "                try: embedding_weights[index,:] = embeddings[word]\n",
    "                except: embedding_weights[index,:] = np.random.rand( 1 , embeddings_dim )\n",
    "    np.random.seed(seed)\n",
    "    filter_length = 3\n",
    "    nb_filter = embeddings_dim\n",
    "    pool_length = 2\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, embeddings_dim, input_length=max_sent_len, weights=[embedding_weights]))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Convolution1D(filters=32, kernel_size=3, activation='relu'))\n",
    "    model.add(MaxPooling1D())\n",
    "    model.add(LSTM(embeddings_dim))\n",
    "    model.add(Dense(reg_dimensions))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "    train_sequences = np.array(train_sequences)\n",
    "    train_labels = np.array(train_labels)\n",
    "    model.fit( train_sequences , train_labels , epochs=30, batch_size=16)\n",
    "    model.save(\"/content/emotion-intensity-prediction-/keras_regression/models/\"+currentemo+\".h5\")  # creates a HDF5 file 'my_model.h5'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21d3cf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = np.array(test_sequences)\n",
    "results = model.predict( test_sequences )\n",
    "# np.savetxt(\"/content/emotion-intensity-prediction-/keras_regression/test/pred/\"+currentemo+\".txt\", results, newline='\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7595d66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "test_labels = np.array(test_labels)\n",
    "mse = mean_squared_error(test_labels, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60c92c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01911054209786421"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03fe98e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.40739197]\n",
      " [0.27555066]\n",
      " [0.5218489 ]\n",
      " [0.5577313 ]\n",
      " [0.5289149 ]\n",
      " [0.64020413]\n",
      " [0.38352755]\n",
      " [0.60591066]\n",
      " [0.36625522]\n",
      " [0.3169623 ]\n",
      " [0.56976134]\n",
      " [0.5775158 ]\n",
      " [0.4044249 ]\n",
      " [0.6542872 ]\n",
      " [0.5405839 ]\n",
      " [0.44410327]\n",
      " [0.42767614]\n",
      " [0.51057434]\n",
      " [0.5212598 ]\n",
      " [0.4728461 ]\n",
      " [0.61563355]\n",
      " [0.4869023 ]\n",
      " [0.52743626]\n",
      " [0.55211246]\n",
      " [0.37357488]\n",
      " [0.54482114]\n",
      " [0.50874007]\n",
      " [0.57501644]\n",
      " [0.5831641 ]\n",
      " [0.48305795]\n",
      " [0.38601747]\n",
      " [0.5208992 ]\n",
      " [0.64838195]\n",
      " [0.57481885]\n",
      " [0.5709633 ]\n",
      " [0.62930095]\n",
      " [0.44189745]\n",
      " [0.50338554]\n",
      " [0.53495103]\n",
      " [0.81197244]\n",
      " [0.73296404]\n",
      " [0.47111973]\n",
      " [0.45221528]\n",
      " [0.6539094 ]\n",
      " [0.5470284 ]\n",
      " [0.6619128 ]\n",
      " [0.5296949 ]\n",
      " [0.40485543]\n",
      " [0.52308166]\n",
      " [0.50044334]\n",
      " [0.4553193 ]\n",
      " [0.63059956]\n",
      " [0.5154291 ]\n",
      " [0.42319557]\n",
      " [0.7297125 ]\n",
      " [0.29121372]\n",
      " [0.2758641 ]\n",
      " [0.5014823 ]\n",
      " [0.5424186 ]\n",
      " [0.43000653]\n",
      " [0.47626245]\n",
      " [0.43422073]\n",
      " [0.42052764]\n",
      " [0.525714  ]\n",
      " [0.5200603 ]\n",
      " [0.41297847]\n",
      " [0.48041734]\n",
      " [0.46300375]\n",
      " [0.63121104]\n",
      " [0.3744856 ]\n",
      " [0.40941668]\n",
      " [0.3341847 ]\n",
      " [0.5119761 ]\n",
      " [0.19691214]\n",
      " [0.3757224 ]\n",
      " [0.36014438]\n",
      " [0.4705212 ]\n",
      " [0.52828294]\n",
      " [0.5053429 ]\n",
      " [0.57752174]\n",
      " [0.5150604 ]\n",
      " [0.5300816 ]\n",
      " [0.51298577]\n",
      " [0.55740994]\n",
      " [0.467445  ]\n",
      " [0.6564509 ]\n",
      " [0.5001432 ]\n",
      " [0.5425838 ]\n",
      " [0.5766369 ]\n",
      " [0.41625792]\n",
      " [0.38569272]\n",
      " [0.47956935]\n",
      " [0.45434576]\n",
      " [0.5565179 ]\n",
      " [0.6500981 ]\n",
      " [0.6488446 ]\n",
      " [0.670352  ]\n",
      " [0.667664  ]\n",
      " [0.48935455]\n",
      " [0.4637208 ]\n",
      " [0.5119288 ]\n",
      " [0.48449242]\n",
      " [0.46654403]\n",
      " [0.6325235 ]\n",
      " [0.43752795]\n",
      " [0.54332846]\n",
      " [0.49744773]\n",
      " [0.35244644]\n",
      " [0.45101714]\n",
      " [0.40417373]\n",
      " [0.3976704 ]\n",
      " [0.43244484]\n",
      " [0.64461577]\n",
      " [0.45232698]\n",
      " [0.500143  ]\n",
      " [0.5013307 ]\n",
      " [0.47638863]\n",
      " [0.36770982]\n",
      " [0.46252978]\n",
      " [0.51286983]\n",
      " [0.422823  ]\n",
      " [0.38376653]\n",
      " [0.53872776]\n",
      " [0.42752346]\n",
      " [0.44383135]\n",
      " [0.40681225]\n",
      " [0.4239099 ]\n",
      " [0.45846552]\n",
      " [0.42772716]\n",
      " [0.51496994]\n",
      " [0.47553837]\n",
      " [0.5904046 ]\n",
      " [0.5006762 ]\n",
      " [0.4627945 ]\n",
      " [0.43574452]\n",
      " [0.34207684]\n",
      " [0.4101243 ]\n",
      " [0.52738667]\n",
      " [0.39602083]\n",
      " [0.45075768]\n",
      " [0.58893466]\n",
      " [0.520198  ]\n",
      " [0.55296385]\n",
      " [0.44321775]\n",
      " [0.6254983 ]\n",
      " [0.46241865]\n",
      " [0.40029645]\n",
      " [0.68817854]\n",
      " [0.5427892 ]\n",
      " [0.5773841 ]\n",
      " [0.4272492 ]\n",
      " [0.5749799 ]\n",
      " [0.5014285 ]\n",
      " [0.48997474]\n",
      " [0.48128146]\n",
      " [0.5470742 ]\n",
      " [0.6305569 ]\n",
      " [0.54542464]\n",
      " [0.4868745 ]\n",
      " [0.42697588]\n",
      " [0.58928895]\n",
      " [0.452676  ]\n",
      " [0.44531566]\n",
      " [0.4857978 ]\n",
      " [0.37026483]\n",
      " [0.47794074]\n",
      " [0.46341586]\n",
      " [0.39769226]\n",
      " [0.58356476]\n",
      " [0.6955757 ]\n",
      " [0.45580444]\n",
      " [0.48101333]\n",
      " [0.50327826]\n",
      " [0.46040827]\n",
      " [0.5506474 ]\n",
      " [0.40061575]\n",
      " [0.36977154]\n",
      " [0.60247594]\n",
      " [0.5710795 ]\n",
      " [0.45311436]\n",
      " [0.49964327]\n",
      " [0.39477667]\n",
      " [0.51005125]\n",
      " [0.4678322 ]\n",
      " [0.49655634]\n",
      " [0.47009057]\n",
      " [0.5546159 ]\n",
      " [0.44516772]\n",
      " [0.41119045]\n",
      " [0.66676366]\n",
      " [0.5477354 ]\n",
      " [0.50596625]\n",
      " [0.65953946]\n",
      " [0.4427747 ]\n",
      " [0.49722937]\n",
      " [0.42637593]\n",
      " [0.4184486 ]\n",
      " [0.6315718 ]\n",
      " [0.44329998]\n",
      " [0.52831405]\n",
      " [0.5659083 ]\n",
      " [0.4787532 ]\n",
      " [0.5102646 ]\n",
      " [0.48598585]\n",
      " [0.521176  ]\n",
      " [0.477264  ]\n",
      " [0.40298322]\n",
      " [0.4083121 ]\n",
      " [0.34783077]\n",
      " [0.2640277 ]\n",
      " [0.32190996]\n",
      " [0.5232896 ]\n",
      " [0.48696926]\n",
      " [0.5065502 ]\n",
      " [0.6648127 ]\n",
      " [0.57708454]\n",
      " [0.419065  ]\n",
      " [0.46936333]\n",
      " [0.48044795]\n",
      " [0.60150385]\n",
      " [0.6083129 ]\n",
      " [0.4523452 ]\n",
      " [0.4390317 ]\n",
      " [0.4190743 ]\n",
      " [0.5149953 ]\n",
      " [0.67535204]\n",
      " [0.41660702]\n",
      " [0.3964402 ]\n",
      " [0.5007114 ]\n",
      " [0.4482499 ]\n",
      " [0.42478055]\n",
      " [0.48324722]\n",
      " [0.45910996]\n",
      " [0.672507  ]\n",
      " [0.46071744]\n",
      " [0.44141155]\n",
      " [0.38494417]\n",
      " [0.54138166]\n",
      " [0.4802943 ]\n",
      " [0.4000357 ]\n",
      " [0.49652633]\n",
      " [0.49452385]\n",
      " [0.6079391 ]\n",
      " [0.518649  ]\n",
      " [0.4749443 ]\n",
      " [0.46112096]\n",
      " [0.67146385]\n",
      " [0.6124362 ]\n",
      " [0.49721935]\n",
      " [0.56709045]\n",
      " [0.5348596 ]\n",
      " [0.45503157]\n",
      " [0.5539617 ]\n",
      " [0.4714794 ]\n",
      " [0.49647114]\n",
      " [0.41303396]\n",
      " [0.6083148 ]\n",
      " [0.38136446]\n",
      " [0.41547853]\n",
      " [0.51920927]\n",
      " [0.56154156]\n",
      " [0.44076377]\n",
      " [0.5944716 ]\n",
      " [0.5268712 ]\n",
      " [0.6030307 ]\n",
      " [0.519704  ]\n",
      " [0.47130913]\n",
      " [0.62180656]\n",
      " [0.58281785]\n",
      " [0.5232734 ]\n",
      " [0.5263256 ]\n",
      " [0.59059274]\n",
      " [0.5585016 ]\n",
      " [0.69431126]\n",
      " [0.5309056 ]\n",
      " [0.44523382]\n",
      " [0.489266  ]\n",
      " [0.45573837]\n",
      " [0.5397142 ]\n",
      " [0.48441115]\n",
      " [0.48690557]\n",
      " [0.4215993 ]\n",
      " [0.35859683]\n",
      " [0.6868969 ]\n",
      " [0.31663668]\n",
      " [0.4125209 ]\n",
      " [0.6094294 ]\n",
      " [0.4609922 ]\n",
      " [0.53128433]\n",
      " [0.45953023]\n",
      " [0.6495722 ]\n",
      " [0.43145415]\n",
      " [0.40731162]\n",
      " [0.6115396 ]\n",
      " [0.46398932]\n",
      " [0.57146853]\n",
      " [0.42119253]\n",
      " [0.61777425]\n",
      " [0.4563111 ]\n",
      " [0.6936925 ]\n",
      " [0.57765865]\n",
      " [0.52764624]\n",
      " [0.6327571 ]\n",
      " [0.40882456]\n",
      " [0.45582718]\n",
      " [0.44016248]\n",
      " [0.42339668]\n",
      " [0.5174828 ]\n",
      " [0.399242  ]\n",
      " [0.5962922 ]\n",
      " [0.40653008]\n",
      " [0.38695782]\n",
      " [0.4466387 ]\n",
      " [0.4722581 ]\n",
      " [0.45956725]\n",
      " [0.4400235 ]\n",
      " [0.48768806]\n",
      " [0.42988384]\n",
      " [0.50372225]\n",
      " [0.34308714]\n",
      " [0.43577033]\n",
      " [0.6388966 ]\n",
      " [0.50205255]\n",
      " [0.48063183]\n",
      " [0.4258169 ]\n",
      " [0.4701533 ]\n",
      " [0.5529494 ]\n",
      " [0.48185968]\n",
      " [0.43734652]\n",
      " [0.6421931 ]\n",
      " [0.44141716]\n",
      " [0.5117369 ]\n",
      " [0.42555767]\n",
      " [0.67755985]\n",
      " [0.49502888]\n",
      " [0.3944901 ]\n",
      " [0.45719963]\n",
      " [0.43406785]\n",
      " [0.48481202]\n",
      " [0.4465972 ]\n",
      " [0.39426875]\n",
      " [0.4914653 ]\n",
      " [0.6328781 ]\n",
      " [0.4471149 ]\n",
      " [0.4766554 ]\n",
      " [0.4102552 ]\n",
      " [0.5886637 ]\n",
      " [0.4391202 ]\n",
      " [0.4616572 ]\n",
      " [0.55106217]\n",
      " [0.39911783]\n",
      " [0.43772632]\n",
      " [0.3725775 ]\n",
      " [0.4485183 ]\n",
      " [0.50841963]\n",
      " [0.5000411 ]\n",
      " [0.47960788]\n",
      " [0.4582705 ]\n",
      " [0.4819809 ]\n",
      " [0.44451144]\n",
      " [0.76530606]\n",
      " [0.49628687]\n",
      " [0.49800122]\n",
      " [0.71104246]\n",
      " [0.6173799 ]\n",
      " [0.5394556 ]\n",
      " [0.45229074]\n",
      " [0.5149228 ]\n",
      " [0.52668506]\n",
      " [0.6171674 ]\n",
      " [0.44784635]\n",
      " [0.43847126]\n",
      " [0.5123306 ]\n",
      " [0.35064232]\n",
      " [0.45469517]\n",
      " [0.38729414]\n",
      " [0.5079346 ]\n",
      " [0.29425734]\n",
      " [0.30636302]\n",
      " [0.47460002]\n",
      " [0.5016295 ]\n",
      " [0.48474064]\n",
      " [0.45218685]\n",
      " [0.49719363]\n",
      " [0.24816054]\n",
      " [0.38080704]\n",
      " [0.5602235 ]\n",
      " [0.38317984]\n",
      " [0.7498329 ]\n",
      " [0.5377351 ]\n",
      " [0.40775707]\n",
      " [0.40820006]\n",
      " [0.40857968]\n",
      " [0.47580707]\n",
      " [0.76805806]\n",
      " [0.47219688]\n",
      " [0.5455445 ]\n",
      " [0.35003287]\n",
      " [0.3925025 ]\n",
      " [0.33845672]\n",
      " [0.45919627]\n",
      " [0.49888077]\n",
      " [0.4885988 ]\n",
      " [0.60519195]\n",
      " [0.43694264]\n",
      " [0.46249783]\n",
      " [0.38512367]\n",
      " [0.38495344]\n",
      " [0.4850088 ]\n",
      " [0.39509043]\n",
      " [0.69808125]\n",
      " [0.5117205 ]\n",
      " [0.4659584 ]\n",
      " [0.51373786]\n",
      " [0.6385156 ]\n",
      " [0.59863234]\n",
      " [0.4743888 ]\n",
      " [0.6873839 ]\n",
      " [0.5319053 ]\n",
      " [0.70825654]\n",
      " [0.30884022]\n",
      " [0.5202056 ]\n",
      " [0.48875722]\n",
      " [0.6283467 ]\n",
      " [0.461902  ]\n",
      " [0.49663925]\n",
      " [0.43290064]\n",
      " [0.75750566]\n",
      " [0.59153616]\n",
      " [0.33467358]\n",
      " [0.4312366 ]\n",
      " [0.38504186]\n",
      " [0.45429188]\n",
      " [0.60378635]\n",
      " [0.47114307]\n",
      " [0.68925166]\n",
      " [0.5771467 ]\n",
      " [0.47826737]\n",
      " [0.5862149 ]\n",
      " [0.5110182 ]\n",
      " [0.5439739 ]\n",
      " [0.4190668 ]\n",
      " [0.4796101 ]\n",
      " [0.60832983]\n",
      " [0.40856338]\n",
      " [0.3884498 ]\n",
      " [0.5824632 ]\n",
      " [0.46353033]\n",
      " [0.5286269 ]\n",
      " [0.492377  ]\n",
      " [0.4930699 ]\n",
      " [0.48313817]\n",
      " [0.6417953 ]\n",
      " [0.47706217]\n",
      " [0.40052253]\n",
      " [0.42231435]\n",
      " [0.40773374]\n",
      " [0.44553357]\n",
      " [0.4008063 ]\n",
      " [0.5686948 ]\n",
      " [0.45887432]\n",
      " [0.6057703 ]\n",
      " [0.57678187]\n",
      " [0.5519166 ]\n",
      " [0.39127254]\n",
      " [0.34170625]\n",
      " [0.38303518]\n",
      " [0.31259462]\n",
      " [0.46968827]\n",
      " [0.4481178 ]\n",
      " [0.49984306]\n",
      " [0.48695347]\n",
      " [0.49783972]\n",
      " [0.41549066]\n",
      " [0.5016299 ]\n",
      " [0.39713064]\n",
      " [0.3807251 ]\n",
      " [0.41047686]\n",
      " [0.55511534]\n",
      " [0.36005515]\n",
      " [0.63700134]\n",
      " [0.465436  ]\n",
      " [0.48487815]\n",
      " [0.47938606]\n",
      " [0.44502214]\n",
      " [0.59164643]\n",
      " [0.5369226 ]\n",
      " [0.44013742]\n",
      " [0.56200284]\n",
      " [0.4832692 ]\n",
      " [0.54130024]\n",
      " [0.47318727]\n",
      " [0.3403501 ]\n",
      " [0.49965984]\n",
      " [0.3741936 ]\n",
      " [0.5091572 ]\n",
      " [0.6072213 ]\n",
      " [0.49202335]\n",
      " [0.8254614 ]\n",
      " [0.688066  ]\n",
      " [0.6179386 ]\n",
      " [0.42438287]\n",
      " [0.4850788 ]\n",
      " [0.36435795]\n",
      " [0.4685116 ]\n",
      " [0.44551158]\n",
      " [0.4778348 ]\n",
      " [0.44805178]\n",
      " [0.5297427 ]\n",
      " [0.55610394]\n",
      " [0.6293774 ]\n",
      " [0.42193428]\n",
      " [0.40314725]\n",
      " [0.5650355 ]\n",
      " [0.43450677]\n",
      " [0.33832252]\n",
      " [0.37483388]\n",
      " [0.56247574]\n",
      " [0.5776501 ]\n",
      " [0.43263   ]\n",
      " [0.4472702 ]\n",
      " [0.38690668]\n",
      " [0.52500093]\n",
      " [0.47403583]\n",
      " [0.49337476]\n",
      " [0.38816968]\n",
      " [0.33010077]\n",
      " [0.42349923]\n",
      " [0.3902419 ]\n",
      " [0.49467486]\n",
      " [0.5132069 ]\n",
      " [0.48014718]\n",
      " [0.46646786]\n",
      " [0.39510012]\n",
      " [0.4267667 ]\n",
      " [0.3951292 ]\n",
      " [0.5908522 ]\n",
      " [0.58289987]\n",
      " [0.52292514]\n",
      " [0.50535625]\n",
      " [0.4611881 ]\n",
      " [0.42544734]\n",
      " [0.51321304]\n",
      " [0.4181962 ]\n",
      " [0.5277781 ]\n",
      " [0.38828775]\n",
      " [0.5943766 ]\n",
      " [0.4940928 ]\n",
      " [0.4678583 ]\n",
      " [0.76083887]\n",
      " [0.52874917]\n",
      " [0.49653548]\n",
      " [0.46913064]\n",
      " [0.56548184]\n",
      " [0.48080233]\n",
      " [0.4701537 ]\n",
      " [0.46440855]\n",
      " [0.7450444 ]\n",
      " [0.73504686]\n",
      " [0.37301666]\n",
      " [0.5146013 ]\n",
      " [0.6588727 ]\n",
      " [0.4552796 ]\n",
      " [0.3217384 ]\n",
      " [0.41827124]\n",
      " [0.44911188]\n",
      " [0.63227683]\n",
      " [0.45468488]\n",
      " [0.28436816]\n",
      " [0.27885437]\n",
      " [0.5849521 ]\n",
      " [0.58052695]\n",
      " [0.41415444]\n",
      " [0.716951  ]\n",
      " [0.53191614]\n",
      " [0.41179645]\n",
      " [0.5225483 ]\n",
      " [0.504287  ]\n",
      " [0.5414313 ]\n",
      " [0.5915293 ]\n",
      " [0.42017883]\n",
      " [0.47590774]\n",
      " [0.4729837 ]\n",
      " [0.4944987 ]\n",
      " [0.48511818]\n",
      " [0.6542019 ]\n",
      " [0.81595004]\n",
      " [0.58025014]\n",
      " [0.41396835]\n",
      " [0.65596795]\n",
      " [0.4303785 ]\n",
      " [0.5305405 ]\n",
      " [0.42640224]\n",
      " [0.4001177 ]\n",
      " [0.44706014]\n",
      " [0.44741797]\n",
      " [0.48460913]\n",
      " [0.60423553]\n",
      " [0.4392044 ]\n",
      " [0.43448436]\n",
      " [0.3944976 ]\n",
      " [0.7160602 ]\n",
      " [0.51068896]\n",
      " [0.43983155]\n",
      " [0.59469974]\n",
      " [0.47400382]\n",
      " [0.5288599 ]\n",
      " [0.539403  ]\n",
      " [0.6664115 ]\n",
      " [0.48515767]\n",
      " [0.5676875 ]\n",
      " [0.4335297 ]\n",
      " [0.42849633]\n",
      " [0.7325618 ]\n",
      " [0.44530386]\n",
      " [0.54376435]\n",
      " [0.50018126]\n",
      " [0.51466477]\n",
      " [0.5493242 ]\n",
      " [0.5507111 ]\n",
      " [0.49930462]\n",
      " [0.34505725]\n",
      " [0.45371473]\n",
      " [0.3343451 ]\n",
      " [0.7133381 ]\n",
      " [0.62298983]\n",
      " [0.63087577]\n",
      " [0.46870965]\n",
      " [0.45543393]\n",
      " [0.8275322 ]\n",
      " [0.57356113]\n",
      " [0.45789477]\n",
      " [0.47102055]\n",
      " [0.50462455]\n",
      " [0.4818361 ]\n",
      " [0.64533746]\n",
      " [0.780977  ]\n",
      " [0.4342585 ]\n",
      " [0.41222578]\n",
      " [0.486597  ]\n",
      " [0.5051629 ]\n",
      " [0.47296768]\n",
      " [0.45231035]\n",
      " [0.66352546]\n",
      " [0.5448872 ]\n",
      " [0.55393535]\n",
      " [0.5604871 ]\n",
      " [0.49383464]\n",
      " [0.32286102]\n",
      " [0.5605385 ]\n",
      " [0.6901139 ]\n",
      " [0.50111365]\n",
      " [0.54365396]\n",
      " [0.4234298 ]\n",
      " [0.5052364 ]\n",
      " [0.37705132]\n",
      " [0.37001124]\n",
      " [0.48358816]\n",
      " [0.40960208]\n",
      " [0.6456194 ]\n",
      " [0.5605621 ]\n",
      " [0.65539324]\n",
      " [0.3881937 ]\n",
      " [0.40130353]\n",
      " [0.48027143]\n",
      " [0.40079612]\n",
      " [0.45804447]\n",
      " [0.40296364]\n",
      " [0.4333978 ]\n",
      " [0.5546835 ]\n",
      " [0.62607014]\n",
      " [0.44324455]\n",
      " [0.32091886]\n",
      " [0.50854516]\n",
      " [0.4983559 ]\n",
      " [0.39060587]\n",
      " [0.35773072]\n",
      " [0.48721704]\n",
      " [0.4667476 ]\n",
      " [0.46342838]\n",
      " [0.3928675 ]\n",
      " [0.46492875]\n",
      " [0.4747269 ]\n",
      " [0.49324697]\n",
      " [0.5625371 ]\n",
      " [0.4478899 ]\n",
      " [0.57723516]\n",
      " [0.44745135]\n",
      " [0.34441864]\n",
      " [0.40839297]\n",
      " [0.5389908 ]\n",
      " [0.5257153 ]\n",
      " [0.73508275]\n",
      " [0.4601349 ]\n",
      " [0.37301797]\n",
      " [0.3394164 ]\n",
      " [0.49505213]\n",
      " [0.37976795]\n",
      " [0.46382922]\n",
      " [0.4938583 ]\n",
      " [0.39777842]\n",
      " [0.45001465]\n",
      " [0.4405778 ]\n",
      " [0.52953076]\n",
      " [0.5610198 ]\n",
      " [0.48888183]\n",
      " [0.43267974]\n",
      " [0.5297384 ]\n",
      " [0.6178576 ]\n",
      " [0.50248027]\n",
      " [0.36570984]\n",
      " [0.455221  ]\n",
      " [0.7352399 ]\n",
      " [0.5563329 ]\n",
      " [0.560838  ]\n",
      " [0.36849   ]\n",
      " [0.6130998 ]\n",
      " [0.43854338]\n",
      " [0.38808197]\n",
      " [0.730817  ]\n",
      " [0.53413   ]\n",
      " [0.54570353]\n",
      " [0.4364765 ]\n",
      " [0.6425807 ]\n",
      " [0.4185779 ]\n",
      " [0.4105518 ]\n",
      " [0.44363052]\n",
      " [0.35006818]\n",
      " [0.4563999 ]\n",
      " [0.4485254 ]\n",
      " [0.50980926]\n",
      " [0.43206298]\n",
      " [0.4209122 ]\n",
      " [0.54910696]\n",
      " [0.5040852 ]\n",
      " [0.39333645]\n",
      " [0.4851678 ]\n",
      " [0.480084  ]\n",
      " [0.5049348 ]\n",
      " [0.49439108]\n",
      " [0.38279182]\n",
      " [0.70220506]\n",
      " [0.6466603 ]\n",
      " [0.47489294]\n",
      " [0.760571  ]\n",
      " [0.8676562 ]\n",
      " [0.4156761 ]\n",
      " [0.4837946 ]\n",
      " [0.4955502 ]\n",
      " [0.53712994]\n",
      " [0.47670528]\n",
      " [0.50474286]\n",
      " [0.64777195]\n",
      " [0.6723702 ]\n",
      " [0.4996808 ]\n",
      " [0.48488748]\n",
      " [0.37216645]\n",
      " [0.43508604]\n",
      " [0.44723013]\n",
      " [0.35772255]]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc2513b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.319 0.144 0.898 0.271 0.646 0.583 0.375 0.625 0.396 0.25  0.438 0.708\n",
      " 0.333 0.877 0.708 0.417 0.229 0.375 0.667 0.354 0.812 0.562 0.312 0.625\n",
      " 0.458 0.521 0.583 0.458 0.271 0.188 0.271 0.708 0.417 0.292 0.771 0.521\n",
      " 0.271 0.729 0.5   0.938 0.917 0.479 0.375 0.648 0.667 0.755 0.792 0.521\n",
      " 0.479 0.5   0.417 0.5   0.396 0.333 0.798 0.375 0.173 0.771 0.625 0.906\n",
      " 0.333 0.438 0.25  0.646 0.5   0.5   0.688 0.479 0.604 0.375 0.458 0.323\n",
      " 0.542 0.229 0.375 0.354 0.465 0.521 0.562 0.292 0.521 0.396 0.646 0.396\n",
      " 0.438 0.875 0.688 0.438 0.396 0.333 0.438 0.583 0.562 0.271 0.833 0.91\n",
      " 0.771 0.851 0.296 0.292 0.479 0.458 0.521 0.492 0.312 0.292 0.562 0.583\n",
      " 0.458 0.229 0.375 0.604 0.583 0.219 0.396 0.354 0.356 0.458 0.354 0.292\n",
      " 0.121 0.417 0.84  0.354 0.271 0.192 0.292 0.438 0.208 0.292 0.688 0.604\n",
      " 0.583 0.354 0.375 0.354 0.333 0.5   0.271 0.25  0.583 0.542 0.5   0.417\n",
      " 0.688 0.417 0.542 0.688 0.312 0.521 0.396 0.375 0.333 0.729 0.708 0.688\n",
      " 0.78  0.688 0.583 0.354 0.438 0.354 0.583 0.454 0.49  0.292 0.542 0.458\n",
      " 0.729 0.708 0.438 0.417 0.417 0.5   0.854 0.292 0.188 0.629 0.708 0.625\n",
      " 0.438 0.354 0.688 0.417 0.653 0.354 0.667 0.625 0.312 0.771 0.75  0.75\n",
      " 0.625 0.271 0.729 0.667 0.354 0.833 0.542 0.604 0.479 0.458 0.521 0.562\n",
      " 0.542 0.396 0.542 0.438 0.604 0.188 0.146 0.583 0.625 0.479 0.676 0.75\n",
      " 0.458 0.75  0.729 0.458 0.812 0.458 0.458 0.685 0.354 0.771 0.625 0.167\n",
      " 0.354 0.667 0.464 0.417 0.521 0.542 0.458 0.396 0.312 0.417 0.211 0.188\n",
      " 0.386 0.479 0.792 0.792 0.438 0.255 0.667 0.646 0.625 0.417 0.438 0.542\n",
      " 0.289 0.438 0.458 0.509 0.458 0.479 0.271 0.542 0.646 0.562 0.896 0.729\n",
      " 0.583 0.417 0.562 0.562 0.542 0.405 0.479 0.75  0.708 0.688 0.271 0.396\n",
      " 0.438 0.361 0.688 0.325 0.479 0.562 0.583 0.75  0.417 0.458 0.729 0.417\n",
      " 0.406 0.375 0.521 0.375 0.667 0.583 0.396 0.604 0.396 0.625 0.396 0.771\n",
      " 0.625 0.438 0.5   0.458 0.542 0.417 0.375 0.53  0.167 0.688 0.375 0.312\n",
      " 0.417 0.292 0.271 0.479 0.533 0.509 0.521 0.438 0.604 0.5   0.396 0.562\n",
      " 0.521 0.312 0.553 0.5   0.562 0.771 0.5   0.333 0.5   0.646 0.479 0.375\n",
      " 0.396 0.646 0.729 0.458 0.468 0.333 0.604 0.562 0.438 0.267 0.646 0.479\n",
      " 0.688 0.438 0.312 0.25  0.375 0.292 0.667 0.604 0.521 0.521 0.438 0.333\n",
      " 0.75  0.458 0.5   0.729 0.562 0.771 0.354 0.583 0.5   0.484 0.667 0.717\n",
      " 0.333 0.438 0.375 0.333 0.542 0.5   0.396 0.396 0.375 0.417 0.333 0.375\n",
      " 0.229 0.125 0.625 0.458 0.583 0.542 0.25  0.229 0.312 0.438 0.688 0.229\n",
      " 0.604 0.333 0.396 0.583 0.333 0.646 0.562 0.562 0.208 0.521 0.375 0.138\n",
      " 0.5   0.458 0.667 0.333 0.396 0.521 0.85  0.667 0.521 0.75  0.583 0.708\n",
      " 0.188 0.583 0.479 0.5   0.604 0.583 0.312 0.901 0.672 0.312 0.667 0.333\n",
      " 0.438 0.771 0.583 0.6   0.667 0.646 0.479 0.479 0.771 0.562 0.417 0.729\n",
      " 0.417 0.419 0.319 0.521 0.438 0.75  0.934 0.737 0.646 0.438 0.396 0.375\n",
      " 0.667 0.375 0.562 0.625 0.729 0.646 0.312 0.646 0.5   0.271 0.521 0.438\n",
      " 0.604 0.25  0.396 0.375 0.417 0.583 0.833 0.271 0.729 0.354 0.354 0.25\n",
      " 0.75  0.438 0.833 0.75  0.529 0.542 0.646 0.417 0.417 0.396 0.663 0.542\n",
      " 0.458 0.417 0.375 0.812 0.708 0.458 0.792 0.583 0.628 0.583 0.458 0.208\n",
      " 0.729 0.458 0.354 0.354 0.792 0.583 0.5   0.438 0.5   0.646 0.722 0.208\n",
      " 0.384 0.604 0.76  0.408 0.292 0.396 0.417 0.333 0.604 0.292 0.096 0.438\n",
      " 0.337 0.75  0.646 0.792 0.604 0.396 0.333 0.229 0.667 0.312 0.604 0.354\n",
      " 0.542 0.354 0.312 0.5   0.396 0.208 0.729 0.667 0.5   0.688 0.554 0.5\n",
      " 0.562 0.562 0.479 0.646 0.625 0.917 0.771 0.479 0.792 0.75  0.25  0.358\n",
      " 0.28  0.438 0.556 0.461 0.479 0.375 0.854 0.667 0.292 0.625 0.438 0.646\n",
      " 0.5   0.448 0.458 0.396 0.375 0.208 0.75  0.542 0.792 0.673 0.771 0.542\n",
      " 0.509 0.625 0.604 0.458 0.542 0.263 0.708 0.604 0.208 0.604 0.479 0.481\n",
      " 0.271 0.708 0.562 0.458 0.292 0.845 0.479 0.741 0.75  0.708 0.479 0.542\n",
      " 0.208 0.906 0.479 0.667 0.625 0.625 0.479 0.562 0.375 0.306 0.562 0.25\n",
      " 0.708 0.688 0.729 0.625 0.531 0.729 0.604 0.479 0.352 0.646 0.394 0.976\n",
      " 0.667 0.333 0.542 0.5   0.521 0.438 0.562 0.583 0.5   0.479 0.562 0.354\n",
      " 0.032 0.521 0.521 0.521 0.458 0.418 0.341 0.312 0.208 0.625 0.5   0.625\n",
      " 0.458 0.646 0.417 0.458 0.521 0.132 0.438 0.229 0.604 0.583 0.729 0.479\n",
      " 0.354 0.542 0.688 0.146 0.438 0.521 0.521 0.625 0.375 0.521 0.417 0.438\n",
      " 0.667 0.509 0.845 0.375 0.333 0.202 0.542 0.604 0.667 0.542 0.198 0.333\n",
      " 0.339 0.372 0.312 0.479 0.583 0.5   0.438 0.396 0.417 0.688 0.333 0.479\n",
      " 0.583 0.521 0.292 0.312 0.917 0.833 0.375 0.295 0.604 0.438 0.375 0.917\n",
      " 0.312 0.646 0.375 0.583 0.5   0.417 0.646 0.312 0.375 0.479 0.646 0.354\n",
      " 0.214 0.625 0.439 0.146 0.417 0.292 0.625 0.698 0.371 0.764 0.75  0.667\n",
      " 0.562 0.875 0.396 0.25  0.438 0.312 0.604 0.708 0.729 0.604 0.292 0.646\n",
      " 0.125 0.542 0.25  0.417]\n"
     ]
    }
   ],
   "source": [
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4da2bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = np.ones(test_labels.shape[0])*np.mean(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da438a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_mse = mean_squared_error(test_labels, baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4b9f453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02950585552458449"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd37f9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
